<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.4.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2017-06-12T22:25:55+08:00</updated><id>http://localhost:4000/</id><title type="html">陆仁杰的博客</title><subtitle>专注技术,分享心得
</subtitle><author><name>Tracy.lu</name></author><entry><title type="html">朴素贝叶斯分类</title><link href="http://localhost:4000/2017/06/12/machine-naive-bayes.html" rel="alternate" type="text/html" title="朴素贝叶斯分类" /><published>2017-06-12T00:00:00+08:00</published><updated>2017-06-12T00:00:00+08:00</updated><id>http://localhost:4000/2017/06/12/machine-naive-bayes</id><content type="html" xml:base="http://localhost:4000/2017/06/12/machine-naive-bayes.html">&lt;blockquote&gt;
  &lt;p&gt;贝叶斯分类是机器学习中一个重要的分类算法，由于其简单高效，所以在实战中非常受欢迎。&lt;/p&gt;

  &lt;p&gt;本文将介绍贝叶斯分类中两个比较典型的算法——朴素贝叶斯与贝叶斯信念网络。&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;基础知识&quot;&gt;基础知识&lt;/h2&gt;

&lt;p&gt;在开始介绍算法之前，我们先温习几个概率论上几个基础知识。&lt;/p&gt;

&lt;h4 id=&quot;1条件概率pab&quot;&gt;1.条件概率:P(A|B)&lt;/h4&gt;
&lt;p&gt;表示在B发生的情况下A发生的概率。&lt;/p&gt;

&lt;p&gt;例如：在一堆棋子中有方形和圆形两种，方形有红色和白色，圆形有黄色和绿色。问，在已知一颗棋子是方形的情况下该棋子是红色的概率是多少。&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;那么这个问题就可以表示成——P(棋子是红色&lt;/td&gt;
      &lt;td&gt;方形棋子)&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;2先验概率&quot;&gt;2.先验概率&lt;/h4&gt;
&lt;p&gt;是在获得某些信息或者依据前，对 P 的不确定性进行猜测。&lt;/p&gt;

&lt;p&gt;例如：下雨之前会刮风，那么在没有观察是否刮风之前求下雨的概率就是先验概率。&lt;/p&gt;

&lt;h4 id=&quot;3后验概率&quot;&gt;3.后验概率&lt;/h4&gt;
&lt;p&gt;“后验”在这里意思是，考虑相关事件已经被检视并且能够得到一些信息。比如在判断到刮风的情况下再预测下雨的概率。&lt;/p&gt;

&lt;p&gt;后验概率包含了先验信息以及观测样本数据提供的后验信息，对先验概率进行了修正，更接近真实情况。&lt;/p&gt;

&lt;h2 id=&quot;贝叶斯定理&quot;&gt;贝叶斯定理&lt;/h2&gt;
&lt;p&gt;&lt;script type=&quot;math/tex&quot;&gt;P(A|B) = \frac{P(B|A)P(A)}{P(B)}&lt;/script&gt;&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;其中P(A&lt;/td&gt;
      &lt;td&gt;B)是在B发生的情况下A发生的可能性。&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;在贝叶斯定理中，每个名词都有约定俗成的名称:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;•	P(A|B)是已知B发生后A的条件概率，也由于得自B的取值而被称作A的后验概率。
•	P(B|A)是已知A发生后B的条件概率，也由于得自A的取值而被称作B的后验概率。
•	P(A)是A的先验概率（或边缘概率）。之所以称为&quot;先验&quot;是因为它不考虑任何B方面的因素。
•	P(B)是B的先验概率或边缘概率。
&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;

&lt;p&gt;按这些术语，贝叶斯定理可表述为：
后验概率 = (相似度*先验概率)/标准化常量&lt;/p&gt;

&lt;p&gt;也就是说，后验概率与先验概率和相似度的乘积成正比。&lt;/p&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;另外，比例P(B&lt;/td&gt;
      &lt;td&gt;A)/P(B)也有时被称作标准相似度（standardised likelihood），贝叶斯定理可表述为：&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;后验概率 = 标准相似度*先验概率&lt;/p&gt;

&lt;h2 id=&quot;朴素贝叶斯&quot;&gt;朴素贝叶斯&lt;/h2&gt;
&lt;p&gt;在实际应用中，特征值可能会包含多个。比如，给定一个人的身高、体重、肤色……等等特征，求这个人是女生的概率。&lt;/p&gt;

&lt;p&gt;那么，概率表达式可以表示为:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(女生|F_1,F_2,\underbrace{\ldots}_{\rm n个特征} ,F_n)&lt;/script&gt;

&lt;p&gt;那么根据贝叶斯定理，这个概率表达式就可以表示成：&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{P(F_1,F_2,\underbrace{\ldots}_{\rm n个特征} ,F_n|女生)P(女生)}{P(F_1,F_2,\underbrace{\ldots}_{\rm n个特征} ,F_n)}&lt;/script&gt;

&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;由于P(女生)和P(F)的概率都是常数，所以我们只需要关注: $$P(F_1,F_2,\underbrace{\ldots}_{\rm n个特征} ,F_n&lt;/td&gt;
      &lt;td&gt;女生)$$&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;要计算上面这个条件概率，成本是非常高的。为了简化计算，我们有了一个”朴素”的假设——特征&lt;strong&gt;F&lt;/strong&gt;向量的所有属性彼此独立。(所以该算法才被称为朴素贝叶斯)&lt;/p&gt;

&lt;p&gt;有了朴素的假设，就有了以下等式:&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(F_1,F_2,\underbrace{\ldots}_{\rm n个特征} ,F_n|女生)=\prod_{i=1}^nP(F_i|女生)&lt;/script&gt;

&lt;p&gt;所以我们只需要挨个计算”在已知是女生情况下出现特征$ F_i $的概率，并求出它们的乘积即可。&lt;/p&gt;

&lt;p&gt;最后要说明的是，我们在处理连续型特征时，我们一般会假设该属性服从高斯分布。&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;P(F_i|女生)=\frac{1}{\sigma\sqrt{2\pi}} e^-\frac{(x-\mu)^2}{2\sigma^2}&lt;/script&gt;

&lt;p&gt;我们可以使用高斯分布函数去计算条件概率的值。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;到这里，关于朴素贝叶斯的内容就已经讲完了。但朴素贝叶斯也有其不足的地方，那就是”朴素”。
 在实际的应用中，所有特征值不太可能完全独立，所以朴素贝叶斯在很多时候表现并不是太好。
 所以，在特征选项存在明显依赖关系时，我们使用贝叶斯分类的效果往往不太理想，所以我将在下一章介绍基于特征依赖的贝叶斯分类——&lt;strong&gt;贝叶斯信念网络&lt;/strong&gt;。&lt;/p&gt;
&lt;/blockquote&gt;</content><author><name>Tracy.lu</name></author><category term="机器学习" /><summary type="html">贝叶斯分类是机器学习中一个重要的分类算法，由于其简单高效，所以在实战中非常受欢迎。 本文将介绍贝叶斯分类中两个比较典型的算法——朴素贝叶斯与贝叶斯信念网络。</summary></entry></feed>