---
layout: post
title: 朴素贝叶斯分类
category: 机器学习
keywords: 机器学习,贝叶斯
---

> 贝叶斯分类是机器学习中一个重要的分类算法，由于其简单高效，所以在实战中非常受欢迎。
>  
> 本文将介绍贝叶斯分类中两个比较典型的算法——朴素贝叶斯与贝叶斯信念网络。

## 基础知识

在开始介绍算法之前，我们先温习几个概率论上几个基础知识。

#### 1.条件概率:P(A|B)
表示在B发生的情况下A发生的概率。

例如：在一堆棋子中有方形和圆形两种，方形有红色和白色，圆形有黄色和绿色。问，在已知一颗棋子是方形的情况下该棋子是红色的概率是多少。

那么这个问题就可以表示成——P(棋子是红色|方形棋子)

#### 2.先验概率
是在获得某些信息或者依据前，对 P 的不确定性进行猜测。

例如：下雨之前会刮风，那么在没有观察是否刮风之前求下雨的概率就是先验概率。

#### 3.后验概率
"后验"在这里意思是，考虑相关事件已经被检视并且能够得到一些信息。比如在判断到刮风的情况下再预测下雨的概率。

后验概率包含了先验信息以及观测样本数据提供的后验信息，对先验概率进行了修正，更接近真实情况。


## 贝叶斯定理
$$ P(A|B) = \frac{P(B|A)P(A)}{P(B)} $$

其中P(A|B)是在B发生的情况下A发生的可能性。

在贝叶斯定理中，每个名词都有约定俗成的名称:

	•	P(A|B)是已知B发生后A的条件概率，也由于得自B的取值而被称作A的后验概率。
	•	P(B|A)是已知A发生后B的条件概率，也由于得自A的取值而被称作B的后验概率。
	•	P(A)是A的先验概率（或边缘概率）。之所以称为"先验"是因为它不考虑任何B方面的因素。
	•	P(B)是B的先验概率或边缘概率。
	
按这些术语，贝叶斯定理可表述为：
后验概率 = (相似度*先验概率)/标准化常量

也就是说，后验概率与先验概率和相似度的乘积成正比。

另外，比例P(B|A)/P(B)也有时被称作标准相似度（standardised likelihood），贝叶斯定理可表述为：

后验概率 = 标准相似度*先验概率


## 朴素贝叶斯
在实际应用中，特征值可能会包含多个。比如，给定一个人的身高、体重、肤色……等等特征，求这个人是女生的概率。

那么，概率表达式可以表示为:

$$ P(女生|F_1,F_2,\underbrace{\ldots}_{\rm n个特征} ,F_n)$$

那么根据贝叶斯定理，这个概率表达式就可以表示成：

$$ \frac{P(F_1,F_2,\underbrace{\ldots}_{\rm n个特征} ,F_n|女生)P(女生)}{P(F_1,F_2,\underbrace{\ldots}_{\rm n个特征} ,F_n)}  $$


由于P(女生)和P(F)的概率都是常数，所以我们只需要关注: $$P(F_1,F_2,\underbrace{\ldots}_{\rm n个特征} ,F_n|女生)$$

要计算上面这个条件概率，成本是非常高的。为了简化计算，我们有了一个"朴素"的假设——特征**F**向量的所有属性彼此独立。(所以该算法才被称为朴素贝叶斯)

有了朴素的假设，就有了以下等式:

  $$P(F_1,F_2,\underbrace{\ldots}_{\rm n个特征} ,F_n|女生)=\prod_{i=1}^nP(F_i|女生)$$ 


所以我们只需要挨个计算"在已知是女生情况下出现特征$ F_i $的概率，并求出它们的乘积即可。

最后要说明的是，我们在处理连续型特征时，我们一般会假设该属性服从高斯分布。

$$ P(F_i|女生)=\frac{1}{\sigma\sqrt{2\pi}} e^-\frac{(x-\mu)^2}{2\sigma^2}$$

我们可以使用高斯分布函数去计算条件概率的值。

 > 到这里，关于朴素贝叶斯的内容就已经讲完了。但朴素贝叶斯也有其不足的地方，那就是"朴素"。
 在实际的应用中，所有特征值不太可能完全独立，所以朴素贝叶斯在很多时候表现并不是太好。
 所以，在特征选项存在明显依赖关系时，我们使用贝叶斯分类的效果往往不太理想，所以我将在下一章介绍基于特征依赖的贝叶斯分类——**贝叶斯信念网络**。
 
 
 
 

